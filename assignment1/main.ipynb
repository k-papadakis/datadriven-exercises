{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A)\n",
    "Consider the following stochastic field: $E(x)=10(1+f(x))$\n",
    "where $f(x)$ is a zero-mean stationary Gaussian field with unit variance and $x \\in [0,5] (m)$.\n",
    "The autocorrelation function for $f$ is $R_f (\\tau) = \\exp‚Å°(-|\\tau|/2)$.\n",
    "\n",
    "1. Use the Karhunen-Loeve series expansion method to generate $N = 5000$ realizations of the field $E(x)$.\n",
    "2. Justify the number of terms you retained in the KL-expansion.\n",
    "3. Calculate the ensemble average and the ensemble variance from these realizations. To which values would they converge as we increase the number $N$ of realizations?\n",
    "\n",
    "---\n",
    "\n",
    "***Answer***\n",
    "\n",
    "Throughout this document we will refer to *Stochastic Finite Element Methods by Vissarion Papadopoulos & Dimitris G. Giovanis* as ***the book***.\n",
    "\n",
    "We focus on the Gaussian field $f(x)$. To perform analysis with it, we center its domain in $[-2.5, 2.5]$ and we have $a = 2.5$.\n",
    "\n",
    "Our covariance function is of the form defined in (2.22) of the book. Solving for its eigenvalues $\\lambda_n$ and eigenfunctions $\\varphi_n$ we get (book 2.24 - 2.28) \n",
    "\n",
    "* For n = odd,\n",
    "    $$\n",
    "    \\lambda_{n}=\\frac{2 b}{1+\\omega_{n}^{2} b^{2}}, \\quad \\varphi_{n}(x)=c_{n} \\cos \\left(\\omega_{n} x\\right)\n",
    "    $$\n",
    "    where $c_n$ is given by \n",
    "    $$\n",
    "    c_{n}=\\frac{1}{\\sqrt{a+\\frac{\\sin \\left(2 \\omega_{n} a\\right)}{2 \\omega_{n}}}}\n",
    "    $$\n",
    "    and $\\omega_{n}$ is obtained from the solution of\n",
    "    $$\n",
    "    \\frac{1}{b}-\\omega_{n} \\tan \\left(\\omega_{n} a\\right)=0 \\quad \\text { in the range }\\left[(n-1) \\frac{\\pi}{a},\\left(n-\\frac{1}{2}\\right) \\frac{\\pi}{a},\\right]\n",
    "    $$\n",
    "\n",
    "*  For $n \\geq 2$ and $n=$ even,\n",
    "    $$\n",
    "    \\lambda_{n}=\\frac{2 b}{1+\\omega_{n}^{2} b^{2}}, \\quad \\varphi_{n}(x)=l_{n} \\sin \\left(\\omega_{n} x\\right)\n",
    "    $$\n",
    "    with\n",
    "    $$\n",
    "    l_{n}=\\frac{1}{\\sqrt{a-\\frac{\\sin \\left(2 \\omega_{n} a\\right)}{2 \\omega_{n}}}}\n",
    "    $$\n",
    "    and $\\omega_{n}$ being the solution of\n",
    "    $$\n",
    "    \\frac{1}{b} \\tan \\left(\\omega_{n} a\\right)+\\omega_{n}=0 \\quad \\text { in the range }\\left[\\left(n-\\frac{1}{2}\\right) \\frac{\\pi}{a}, n \\frac{\\pi}{a},\\right]\n",
    "    $$\n",
    "\n",
    "These equations will be solved numerically.\n",
    "\n",
    "---\n",
    "\n",
    "The truncated Karhunen-Loeve expansion of $M$ principal components is\n",
    "$$\\hat{f}_M(x) = \\sum_{n=1}^{M} \\sqrt{\\lambda_n} \\varphi_n(x - a) \\xi_n$$\n",
    "where $\\xi_n$ are independent standard normal variables since the process is Gaussian (book page 31).\n",
    "\n",
    "Since $\\xi_n$ are uncorrelated (independent actually) and with variance 1 we have that (book 2.21)\n",
    "\n",
    "$$\\textrm{Var}\\left[\\hat{f}_M(x)\\right] = \\sum_{n=1}^{M} \\lambda_n \\varphi_n^2(x - a)$$\n",
    "\n",
    "Integrating over all $x$, since we have that $\\varphi_n$ are orthonormal, we get the *total explained variance* $\\sum_{n=1}^{M} \\lambda_n$\n",
    "\n",
    "Since the variance of $f(x)$ is always 1, integrating it over the domain gives us *total variance* 5.\n",
    "\n",
    "Therefore the *total explained variance ratio* is given by $\\frac{1}{5} \\sum_{n=1}^{M} \\lambda_n$ and a reasonable value for it is 0.99. This is how we will choose our $M$.\n",
    "\n",
    "---\n",
    "\n",
    "We calculate the expected ensemble mean and variance. We use the again the fact that $\\xi_n$ are uncorrelated with mean 0 and variance 1. We also use the fact that the eigenvalues are all non negative since the covariance function is positive semidefinite (Mercer's theorem).\n",
    "\n",
    "We have that $\\forall x \\in [0, 5]$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\textrm{E}\\left[\\hat{f}_M(x)\\right] &= \\sum_{n=1}^{M} \\sqrt{\\lambda_n} \\varphi_n(x - a) \\textrm{E}\\left[ \\xi_n \\right] = 0\\\\\n",
    "\\textrm{Var}\\left[\\hat{f}_M(x)\\right] &= \\sum_{n=1}^{M} \\lambda_n \\varphi_n^2(x - a) \\leq \\sum_{n=1}^{\\infty} \\lambda_n \\varphi_n^2(x - a) = \\textrm{Var}[f(x)] = 1\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "Thus, $\\forall x \\in [0, 5]$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\textrm{E}\\left[ \\hat{E}_M(x) \\right] &= \\textrm{E}\\left[ 10(1 + \\hat{f}_M(x)) \\right] = 10  (1 + \\textrm{E}\\left[ \\hat{f}_M(x) \\right] ) = 10\\\\\n",
    "\\textrm{Var}\\left[ \\hat{E}_M(x) \\right] &= 100 \\; \\textrm{Var}\\left[ \\hat{f}_M(x) \\right] \\leq 100\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "with the upper bound on the variance being tighter as $M$ increases (equality when $M \\to \\infty$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5283a779f5807837812fce11263866c864d8a422e5c42a24f91adecb03b4c460"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
